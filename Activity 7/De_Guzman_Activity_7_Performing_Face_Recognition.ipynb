{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JemDeGuzman/Computer-Vision-Crash-Course/blob/main/Activity%207/De_Guzman_Activity_7_Performing_Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 018\n",
        "Code Title: | Emerging Technologies in CpE 1 - Fundamentals of Computer Vision\n",
        "1st Semester | AY 2023-2024\n",
        "<u>**ACTIVITY NO.** | **TITLE**\n",
        "**Name** | De Guzman, Jemuel Endrew C.\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: | 02-21-2025\n",
        "**Date Submitted**: | 02-21-2025\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to enable students to perform data preparation and face recognition on their own generated dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Utilize data preparation techniques for images.\n",
        "* Perform Face Recognition using multiple algorithms.\n",
        "* Evaluate the performance of different algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBQh8Eyf1EHC"
      },
      "source": [
        "### Preparing the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpAAiS_V1Jfy"
      },
      "source": [
        "Now that we have our data, we need to load these sample pictures into our face recognition algorithms. All face recognition algorithms take two parameters in their `train()` method: an array of images and an array of labels. What do these labels represent? They are the IDs of a certain individual/face so that when face recognition is performed, we not only know the person was recognized but also who—among the many people available in our database—the person is.\n",
        "\n",
        "To do that, we need to create a comma-separated value (CSV) file, which will contain the path to a sample picture followed by the ID of that person."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWqIq9Sz1Svi"
      },
      "source": [
        "**Include a Screenshot of Your Dataset Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SiR2yJQ1W7B"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPA3SGHN1YdC"
      },
      "source": [
        "### Loading the data and recognizing faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q07mfdMq1b2J"
      },
      "source": [
        "Next up, we need to load these two resources (the array of images and CSV file) into the face recognition algorithm, so it can be trained to recognize our face. To do this, we build a function that reads the CSV file and—for each line of the file—loads the image at the corresponding path into the images array and the ID into the labels array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3t3pE6bOTqP"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(im, size=(200, 200)):\n",
        "    im = cv2.equalizeHist(im)  # Normalize brightness/contrast\n",
        "    im = cv2.resize(im, size)  # Ensure consistent size\n",
        "    return im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def read_images(path, sz=None):\n",
        "    c = 0\n",
        "    X, y = [], []\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        return X, y\n",
        "\n",
        "    for dirname, dirnames, filenames in os.walk(path):\n",
        "        for subdirname in dirnames:\n",
        "            subject_path = os.path.join(dirname, subdirname)\n",
        "\n",
        "            for filename in os.listdir(subject_path):\n",
        "                try:\n",
        "                    if filename == \".directory\":\n",
        "                        continue\n",
        "                    filepath = os.path.join(subject_path, filename)\n",
        "\n",
        "                    im = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                    if im is None:\n",
        "                        continue  # Skip unreadable files\n",
        "\n",
        "                    # Resize the images if size is specified\n",
        "                    if sz is not None:\n",
        "                        im = cv2.resize(im, (200, 200))\n",
        "\n",
        "                    X.append(preprocess_image(np.asarray(im, dtype=np.uint8)))\n",
        "                    y.append(c)\n",
        "\n",
        "                except IOError as e:\n",
        "                    print(f\"I/O Error({e.errno}): {e.strerror}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Unexpected error reading {filepath}: {e}\")\n",
        "\n",
        "            c += 1  # Move this outside the inner loop to increment only per subdirectory\n",
        "    return X, y  # Return as a tuple instead of a list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F72wkh80OTqQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def save_images_and_labels_to_csv(images, labels, csv_filename=\"dataset.csv\"):\n",
        "    # Ensure images and labels have the same length\n",
        "    assert len(images) == len(labels), \"Mismatch between number of images and labels\"\n",
        "\n",
        "    with open(csv_filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write header (optional)\n",
        "        num_pixels = images[0].size  # Get the number of pixels in an image\n",
        "        header = [\"label\"] + [f\"pixel{i}\" for i in range(num_pixels-1)]\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write each image and its corresponding label\n",
        "        for img, label in zip(images, labels):\n",
        "            img_flattened = img.flatten()  # Convert image to 1D array\n",
        "            row = np.insert(img_flattened, 0, label)  # Insert label at the beginning\n",
        "            writer.writerow(row)\n",
        "\n",
        "    print(f\"Images and labels saved to {csv_filename}\")\n",
        "\n",
        "# Example usage\n",
        "# Assuming `images` is a list of NumPy arrays (grayscale images)\n",
        "# And `labels` is a list of corresponding labels\n",
        "\n",
        "# Example images and labels (assuming grayscale 200x200 images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAoOyupDOTqQ",
        "outputId": "386bf459-eda9-4bb9-9e87-7c1aaa45588c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images and labels saved to act_7_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "images, labels = read_images(r'C:\\Users\\Jemuel De Guzman\\Desktop\\JupyterFiles\\OpenCV Crash Course\\Activity_7_Python_Files', 200)\n",
        "\n",
        "save_images_and_labels_to_csv(images, labels, \"act_7_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlGLX6p9OTqR",
        "outputId": "3b1a843d-6433-4772-dd6b-a4849e9ea400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[163, 163, 163, ..., 189, 180, 163],\n",
            "       [163, 163, 163, ..., 168, 168, 168],\n",
            "       [163, 163, 163, ..., 168, 180, 180],\n",
            "       ...,\n",
            "       [ 42,  42,  39, ...,  28,  29,  35],\n",
            "       [ 42,  42,  40, ...,  28,  29,  35],\n",
            "       [ 40,  39,  39, ...,  28,  29,  35]], dtype=uint8), array([[164, 166, 164, ..., 146, 150, 159],\n",
            "       [164, 164, 161, ..., 144, 148, 156],\n",
            "       [161, 159, 156, ..., 144, 148, 159],\n",
            "       ...,\n",
            "       [250, 253, 252, ..., 240, 242, 244],\n",
            "       [219, 232, 232, ..., 250, 248, 239],\n",
            "       [214, 216, 203, ..., 251, 252, 247]], dtype=uint8), array([[193, 172, 172, ...,  88,  77, 123],\n",
            "       [218, 211, 185, ...,  83,  93, 116],\n",
            "       [195, 206, 216, ...,  78,  98, 118],\n",
            "       ...,\n",
            "       [  0,   0,   0, ...,  10,   0,   0],\n",
            "       [  0,   0,   0, ...,  10,   8,   0],\n",
            "       [  0,   0,   0, ...,  10,   4,   0]], dtype=uint8), array([[138, 138, 138, ...,  85,  95,  95],\n",
            "       [138, 138, 135, ...,  85,  87,  95],\n",
            "       [138, 135, 134, ...,  85,  86,  95],\n",
            "       ...,\n",
            "       [177, 174, 171, ...,  38,  38,  38],\n",
            "       [178, 175, 171, ...,  38,  38,  38],\n",
            "       [177, 174, 171, ...,  38,  38,  38]], dtype=uint8), array([[ 44,  38,  34, ...,  29,  29,  34],\n",
            "       [ 44,  38,  34, ...,  29,  29,  29],\n",
            "       [ 44,  44,  38, ...,  29,  29,  29],\n",
            "       ...,\n",
            "       [ 96,  73, 119, ..., 238, 238, 238],\n",
            "       [136,  88,  96, ..., 238, 239, 239],\n",
            "       [175, 103,  52, ..., 239, 241, 241]], dtype=uint8), array([[218, 216, 218, ...,  97, 106, 122],\n",
            "       [219, 218, 218, ...,  97, 100, 120],\n",
            "       [218, 213, 212, ...,  97, 106, 112],\n",
            "       ...,\n",
            "       [100, 137, 153, ..., 106, 122, 130],\n",
            "       [103, 106, 135, ..., 141, 138, 150],\n",
            "       [122, 120, 128, ..., 149, 152, 170]], dtype=uint8), array([[249, 249, 251, ..., 227, 227, 227],\n",
            "       [249, 249, 249, ..., 227, 228, 228],\n",
            "       [249, 249, 249, ..., 228, 228, 228],\n",
            "       ...,\n",
            "       [117, 119, 119, ..., 231, 231, 231],\n",
            "       [119, 119, 124, ..., 231, 231, 231],\n",
            "       [117, 113, 121, ..., 231, 231, 231]], dtype=uint8), array([[224, 218, 218, ...,   9,  21,  36],\n",
            "       [236, 229, 229, ...,   9,  26,  36],\n",
            "       [243, 243, 244, ...,  19,  29,  36],\n",
            "       ...,\n",
            "       [ 50,  50,  44, ...,  98,  94,  89],\n",
            "       [ 50,  47,  44, ...,  94,  94,  89],\n",
            "       [ 50,  48,  44, ...,  96,  94,  94]], dtype=uint8), array([[58, 27,  8, ..., 80, 76, 72],\n",
            "       [48, 11,  5, ..., 65, 57, 50],\n",
            "       [30,  6,  4, ..., 44, 42, 48],\n",
            "       ...,\n",
            "       [81, 78, 82, ..., 24, 19, 19],\n",
            "       [91, 85, 82, ..., 27, 22, 19],\n",
            "       [98, 94, 89, ..., 24, 25, 22]], dtype=uint8), array([[238, 245, 248, ..., 227, 228, 228],\n",
            "       [239, 243, 248, ..., 227, 229, 229],\n",
            "       [240, 242, 247, ..., 227, 229, 229],\n",
            "       ...,\n",
            "       [234, 231, 230, ..., 174, 174, 174],\n",
            "       [230, 232, 235, ..., 174, 171, 174],\n",
            "       [250, 251, 252, ..., 171, 171, 180]], dtype=uint8), array([[ 87,  78,  81, ...,  50,  56,  56],\n",
            "       [102,  93,  98, ...,  58,  63,  63],\n",
            "       [131, 124, 118, ...,  63,  71,  71],\n",
            "       ...,\n",
            "       [  0,   1,  24, ..., 239, 238, 239],\n",
            "       [  0,  19, 120, ..., 241, 241, 242],\n",
            "       [  0, 108, 193, ..., 242, 243, 243]], dtype=uint8), array([[251, 251, 251, ..., 189, 135, 235],\n",
            "       [251, 251, 251, ..., 237, 169, 235],\n",
            "       [251, 251, 251, ..., 251, 233, 236],\n",
            "       ...,\n",
            "       [193, 191, 187, ...,  80,  77,  78],\n",
            "       [187, 181, 184, ...,  80,  77,  77],\n",
            "       [177, 175, 179, ...,  78,  78,  78]], dtype=uint8), array([[218, 207, 165, ..., 254, 253, 237],\n",
            "       [211, 219, 202, ..., 252, 250, 235],\n",
            "       [182, 210, 216, ..., 254, 252, 237],\n",
            "       ...,\n",
            "       [ 27,  27,   0, ..., 240, 240, 220],\n",
            "       [  6,   4,   0, ..., 242, 241, 229],\n",
            "       [  4,   0,   0, ..., 243, 233, 179]], dtype=uint8), array([[224, 224, 224, ..., 140, 140, 140],\n",
            "       [224, 224, 224, ..., 140, 140, 140],\n",
            "       [224, 224, 224, ..., 140, 140, 140],\n",
            "       ...,\n",
            "       [218, 214, 209, ..., 194, 190, 194],\n",
            "       [211, 211, 209, ..., 194, 194, 197],\n",
            "       [211, 211, 209, ..., 194, 197, 203]], dtype=uint8), array([[224, 224, 228, ..., 224, 224, 224],\n",
            "       [228, 228, 229, ..., 228, 228, 228],\n",
            "       [236, 236, 236, ..., 228, 228, 228],\n",
            "       ...,\n",
            "       [174, 159, 148, ...,  40,  40,  40],\n",
            "       [176, 162, 153, ...,  40,  31,  40],\n",
            "       [178, 169, 146, ...,  43,  44,  50]], dtype=uint8), array([[255, 255, 255, ..., 255, 255, 255],\n",
            "       [255, 255, 255, ..., 255, 255, 255],\n",
            "       [255, 255, 255, ..., 255, 255, 255],\n",
            "       ...,\n",
            "       [255, 255, 255, ..., 255, 255, 255],\n",
            "       [255, 255, 255, ..., 255, 255, 255],\n",
            "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8), array([[104, 111, 109, ...,   0,   0,   0],\n",
            "       [103, 108, 108, ...,   0,   0,   0],\n",
            "       [109, 101, 101, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [  0,   0,   0, ...,   0,   6,  50],\n",
            "       [  0,   0,   0, ...,  50,   6,  50],\n",
            "       [  0,   0,   0, ...,   2,   9,   3]], dtype=uint8), array([[214, 214, 214, ..., 130, 117, 114],\n",
            "       [214, 214, 214, ..., 130, 117, 114],\n",
            "       [214, 214, 214, ..., 130, 117, 114],\n",
            "       ...,\n",
            "       [ 39,  39,  32, ..., 179, 179, 179],\n",
            "       [ 35,  35,  32, ..., 179, 179, 179],\n",
            "       [ 32,  32,  32, ..., 179, 175, 175]], dtype=uint8), array([[ 36,  36,  36, ..., 254, 254, 255],\n",
            "       [ 36,  36,  36, ..., 254, 254, 255],\n",
            "       [ 36,  36,  36, ..., 253, 254, 254],\n",
            "       ...,\n",
            "       [118, 112, 108, ..., 108, 108, 108],\n",
            "       [112, 108, 104, ..., 104, 104, 104],\n",
            "       [109, 108, 104, ...,  97,  97,  99]], dtype=uint8), array([[245, 245, 244, ..., 207, 208, 209],\n",
            "       [247, 247, 246, ..., 208, 209, 208],\n",
            "       [251, 250, 249, ..., 207, 207, 206],\n",
            "       ...,\n",
            "       [203, 205, 211, ..., 121, 125, 130],\n",
            "       [209, 206, 204, ..., 121, 124, 130],\n",
            "       [209, 207, 207, ..., 121, 124, 128]], dtype=uint8)]\n"
          ]
        }
      ],
      "source": [
        "print(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqn0DEe-OTqR",
        "outputId": "4edbdcf9-1069-4da4-91dd-c0e5475d3255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWNBxCbO2oO-"
      },
      "source": [
        "**Question: Run the function above on your generated dataset. Provide an analysis and note all the challenges you have encountered running this code.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ5IMZcC3wZt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlLWfyvY3xm0"
      },
      "source": [
        "### Performing Face Recognition Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVF9dfTQ30pc"
      },
      "source": [
        "Here is a sample script for testing the Face Recognition Algorithm. In this section, we're going to follow the same process but with different algorithms for face recognitions, namely:\n",
        "- Eigenface Recognition\n",
        "- Fisherface Recognition\n",
        "- Local Binary Pattern Histograms (LBPH) Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYQ19foI4Oe7"
      },
      "outputs": [],
      "source": [
        "def face_rec():\n",
        "  names = ['Jem', 'Yen'] # Put your names here for faces to recognize\n",
        "  [X, y] = read_images(r'C:\\Users\\Jemuel De Guzman\\Desktop\\JupyterFiles\\OpenCV Crash Course\\Activity_7_Python_Files', 200)\n",
        "  y = np.asarray(y, dtype=np.int32)\n",
        "\n",
        "  model = cv2.face.EigenFaceRecognizer_create()\n",
        "  model.train(X, y)\n",
        "\n",
        "  camera = cv2.VideoCapture(0)\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "  while True:\n",
        "    ret, img = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      face_roi = gray[y:y + h, x:x + w]  # Crop the detected face\n",
        "      roi = cv2.resize(face_roi, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "      try:\n",
        "        params = model.predict(roi)\n",
        "        predicted_label, confidence = params\n",
        "\n",
        "        # Dynamic threshold adjustment based on data\n",
        "        threshold = np.mean([confidence]) + 50  # Average confidence + buffer\n",
        "\n",
        "        #print(f\"Predicted: {predicted_label}, Confidence: {confidence}, Threshold: {threshold}\")\n",
        "\n",
        "        if confidence < threshold:\n",
        "            label = names[predicted_label]\n",
        "\n",
        "        else:\n",
        "            label = \"Unknown\"\n",
        "\n",
        "        cv2.putText(img, label, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    cv2.imshow(\"camera\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  face_rec()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dL7n-mc5JO6"
      },
      "source": [
        "---\n",
        "Perform the remaining face recognition techniques by using the same (or modified) process from the sample code:\n",
        "\n",
        "- `model = cv2.face.createFisherFaceRecognizer()`\n",
        "- `model = cv2.face.createLBPHFaceRecognizer()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvuaNGVJOTqS"
      },
      "outputs": [],
      "source": [
        "# fisher Face recognizer\n",
        "def face_rec():\n",
        "  names = ['Jem', 'Yen'] # Put your names here for faces to recognize\n",
        "  [X, y] = read_images(r'C:\\Users\\Jemuel De Guzman\\Desktop\\JupyterFiles\\OpenCV Crash Course\\Activity_7_Python_Files', 200)\n",
        "  y = np.asarray(y, dtype=np.int32)\n",
        "\n",
        "  model = cv2.face.FisherFaceRecognizer_create()\n",
        "  model.train(X, y)\n",
        "\n",
        "  camera = cv2.VideoCapture(0)\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "  while True:\n",
        "    ret, img = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "      gray = cv2.cvtColor(img[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
        "      roi = cv2.resize(gray, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "      try:\n",
        "        params = model.predict(roi)\n",
        "        label = names[params[0]]\n",
        "        cv2.putText(img, label + \", \" + str(params[1]), (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    cv2.imshow(\"fisherfacerecognizer\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  face_rec()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79Ih9FWiOTqS",
        "outputId": "dd4111f8-c4ec-434e-c5f8-090c51ac01ea"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv_contrib\\modules\\face\\src\\lbph_faces.cpp:362: error: (-210:Unsupported format or combination of formats) Empty training data was given. You'll need more than one sample to learn a model. in function 'cv::face::LBPH::train'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m   cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 40\u001b[0m   \u001b[43mface_rec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mface_rec\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mface\u001b[38;5;241m.\u001b[39mLBPHFaceRecognizer_create()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m camera \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m face_cascade \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv_contrib\\modules\\face\\src\\lbph_faces.cpp:362: error: (-210:Unsupported format or combination of formats) Empty training data was given. You'll need more than one sample to learn a model. in function 'cv::face::LBPH::train'\n"
          ]
        }
      ],
      "source": [
        "# LBPH Face Recognizer\n",
        "def face_rec():\n",
        "  names = ['Jem', 'Yen'] # Put your names here for faces to recognize\n",
        "  [X, y] = read_images(r'C:\\Users\\Jemuel De Guzman\\Desktop\\JupyterFiles\\OpenCV Crash Course\\Activity_7_Python_Files', 200)\n",
        "  y = np.asarray(y, dtype=np.int32)\n",
        "\n",
        "  model = cv2.face.LBPHFaceRecognizer_create()\n",
        "  model.train(X, y)\n",
        "\n",
        "  camera = cv2.VideoCapture(0)\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "  while True:\n",
        "    ret, img = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "      gray = cv2.cvtColor(img[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
        "      roi = cv2.resize(gray, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "      try:\n",
        "        params = model.predict(roi)\n",
        "        label = names[params[0]]\n",
        "        cv2.putText(img, label + \", \" + str(params[1]), (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    cv2.imshow(\"LBPHrecognizer\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  face_rec()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb6Zeh9S5Y1o"
      },
      "source": [
        "**Question: The `predict()` method returns a two-element array. Provide your analysis of the two returned values and their important ince this application.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgo4nuQt506X"
      },
      "source": [
        "Your accomplisment of the tasks below contribute to the achievement of ILO1, ILO2, and ILO3 for this module.\n",
        "\n",
        "---\n",
        "\n",
        "Tasks:\n",
        "1. Create a new dataset for testing, this dataset must include the following:\n",
        "  - The same person/s that the model has to recognize.\n",
        "  - Different person/s that the model should not recognize.\n",
        "2. For each model, perform 20 tests. Document the testing performed and provide observations.\n",
        "3. Conclude on the performed tests by providing your evaluation of the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw8kmZRfOTqT",
        "outputId": "1e40556d-a9c9-4695-d140-789077980228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "def face_rec():\n",
        "  names = ['Jem', 'Yen'] # Put your names here for faces to recognize\n",
        "  [X, y] = read_images(r'C:\\Users\\Jemuel De Guzman\\Desktop\\JupyterFiles\\OpenCV Crash Course\\Activity_7_Python_Files', 200)\n",
        "  print(y)\n",
        "  y = np.asarray(y, dtype=np.int32)\n",
        "\n",
        "  model = cv2.face.EigenFaceRecognizer_create()\n",
        "  model.train(X, y)\n",
        "\n",
        "  camera = cv2.VideoCapture(0)\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "  while True:\n",
        "    ret, img = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "      gray = cv2.cvtColor(img[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
        "      roi = cv2.resize(gray, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "      try:\n",
        "        params = model.predict(roi)\n",
        "        label = names[params[0]]\n",
        "        cv2.putText(img, label + \", \" + str(params[1]), (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    cv2.imshow(\"EigenFace\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  face_rec()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKTS2WGlOTqT"
      },
      "source": [
        "The evaluation of the performance of the face recognition models is that the LBPH and the eigen face performed better than the fisher algorithm because it got more misclassifications than the other two algorithms, I also observed that in my model it is harding to recognize what face to classify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "**From this activity, I was able to learn about how to use facial detection software for machine learning, allowing the computer to recognize the people in images using OpenCV. By using the package, I am able to detect people based on training data. While the model struggles a lot in detecting others, it depends on how well the training data is presented to the model and through the use of proper image processing, we can ensure that this happens.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ElMxAUPJGYLw",
        "X-RNZovNGV9k",
        "Mkyd0KjtGl79",
        "KQspxP0IGoO1"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}